# 一、介绍、体系结构、特点

## 1. 什么是数据仓库

数据仓库是为了帮助企业各个级别进行**决策支持、分析性报告**，提供所有数据类型的战略集合，是为了便于**多维分析和多角度展现**而将数据按特定的模式进行存储所建立起来的关系型数据库，它的数据基于**OLTP源系统**。数据仓库是依照**分析需求、分析维度、分析指标**进行设计的

## 2. 数据仓库体系结构

数据源 -- ETL工程 - 数据仓库存储和管理 - 数据集市(OLAP) - BI工具(数据查询、数据报表、数据分，各类应用)

+ 数据源：业务数据、数据库数据(OLTP)、文档数据、日志数据等

![数据仓库体系结构](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.jpg)

## 3. 数据仓库的特点

+ 面向主题的(Subject-Oriented): 数据仓库中的数据是按照一定的主题域进行组织

  主题：是指用户使用数据仓库进行决策时所关心的重点方面,一个主题通常与多个操作型信息系统(数据库)相关

+ 集成的(Integrated): 数据仓库中的综合数据不能从原来分散的数据库系统直接得到，而是多个不同时间点的数据库快照的集合，基于这些快照进行统计、综合和重组后增加到数据仓库中去

+ 反应历史变化的(Time Variant)：数据仓库随着时间变化不断增加新的数据内容、不断删去旧的数据内容、不断更新综合数据

+ 不可修改的(Unchangeable): 数据仓库涉及到的数据操作主要是数据查询，一般情况下并不进行修改操作

  注意：此时的‘不可修改’是针对应用来说的，也就是说，数据仓库的用户进行分析处理是不进行数据更新操作的。但并不是说，在从数据集成输入数据仓库开始到最后被删除的整个生存周期中，所有的数据仓库数据都是永远不变的

# 二、数据仓库粒度确定

## 1. 粒度级别

**粒度：**是指数据仓库的数据单位中**保存数据的细化或综合程度的级别**，细节程度越高，粒度级别就越低；细节程度越低，粒度级别就越高

+ 当数据仓库的空间很有限时，用高粒度级表示数据将比使用低粒度级表示数据的效率要高得多，并且存放数据所需要的字节数和索引项会少很多
+ 低粒度级实际上可以回答任何问题，但在高粒度级上，数据所能处理的问题的数量是有限的
+ 总结：**高粒度查询快，而低粒度可以解决的问题比较多**

>  设计数据仓库时需要考虑的三大因素
>
> + 数据量大小
> + 原始空间
> + 处理能力

通常，为了节省所用的存储空间、所需的索引项、以及处理数据的处理器资源，在数据仓库中会将数据进行压缩。

在一个**DSS（决策支持系统）**环境中**查询总体性的问题**比查询单个事件要常见的**多**，它既可以在高粒度级上也可以在低粒度级上得到回答，在不同的粒度级上所使用的资源具有很大的差异。在低粒度级需要查询每一条记录，所以需要大量的资源来回答这个问题。但在高粒度级上，数据进行了很大的压缩，只需要查询很少的记录就能得到一个答案。**如果在高粒度级上包括了足够的细节，则使用高粒度级数据的效率将会高得多**

## 2. 数仓分类

基于粒度将数据仓库分为以下三种类型：

+ 低粒度高细节数仓：如每个客户每个月的每个通话记录
+ 高粒度低细节数仓：如每个客户每个月的综合通话记录
+ 双粒度数仓：两者共存，当用户十分需要提高存储与访问数据的效率，以及非常详细地分析数据的能力

![双粒度](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E5%8F%8C%E7%B2%92%E5%BA%A6.jpg)

确定数据粒度是数据仓库设计的基础，当数据粒度合理确定后，设计和实现的其他问题就会变得非常容易。相反，如果没有合理地确定粒度，后续的工作就会很难进行下去。在设计和构造数据仓库之初就必须仔细考虑这种权衡。

# 三、数据仓库和数据库的区别

+ 数据量：数据仓库要比数据库庞大得多
+ 用途：数据库用来处理实际的业务，在生产环境就是用来干活的；数据仓库主要用于数据挖掘和数据分析**，辅助领导做决策
+ 数据来源：数据库的数据来自于业务，数据仓库的数据来源于多个数据库
+ 时间维度：数据库只保留当前信息，数据仓库保留数据时间轴上的全部信息
+ 组织方式：数据库是面向业务组织，数据仓库是面向主题组织
+ 建模方式：数据库服从范式建模，数据仓库一般是合理冗余的
+ 设计目的：数据库以存储、管理为主，数据仓库以组织、计算为主

> **数据库与数据仓库的区别实际讲的是OLTP与OLAP的区别**

操作型处理，叫联机事务处理OLTP(On-Line Transaction Processing)：也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对**少数记录**进行查询、修改。用户较为关心操作的**响应时间、数据的安全性、完整性和并发的支持用户数**等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理

分析型处理，叫联机分析处理OLAP(On-Line Analytical Processing)：一般针对某些主题历史数据进行分析，支持管理决策

# 四、OLTP和OLAP的区别
## 1. OLTP
On-Line Transaction Processing(联机事务处理过程)：也称为面向交易的处理过程，其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作快速响应的方式之一

OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行转账:开启事务 - 从转出账号中扣钱 - 往转入账号中加钱 - 提交事务

## 2. OLAP
On-Line Analytic Processing（联机分析处理过程): OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。如商品推荐：抽取(读取)历史订单 - 分析历时订单，找到最受欢迎的商品 - 展示结果

OLAP适用场景的关键特征
  + 大多数是读请求
  + 数据总是以相当大的批(大于1万行)进行写入
  + 不修改已添加数据
  + 每次查询都是从数据库中读取大量的行，但同时又仅需要少量的列
  + 宽表，即每个表包含着大量的列
  + 较少的查询，每天服务器每秒数百个查询或更少
  + 对于简单查询，允许延迟大约为50毫秒
  + 列中的数据相对较小：数字和字符串
  + 处理单个查询时需要高吞吐量，每个服务器每秒高达数十亿行
  + 事务不是必须的
  + 对于数据一执行性要求低
  + 每一个查询除了一个大表都很小
  + 查询结果明显小于源数据，即数据被过滤或聚合后能够被盛饭在单台服务器的内存中
总结：OLAP场景相对OLTP或Key-Value数据库在处理数据分析查询更高效

## 3. 两者区别
|      |   OLTP    |   OLAP   |
| ---- | ---- | ---- |
|  用户    |  操作人员、低层管理人员    |   决策人员、高级管理人员   |
|  功能    |  日常操作处理    |  分析决策    |
|  数据库设计    |  面向应用    |  面向主题    |
|  数据   |  当前的、最新的、细节的、二维的、分立的    |  历史的、聚集的、多维的、集成的、统一的    |
|  存取 | 读/写少量数据| 读上百万条数据 |
| 工作单位 | 简单的事务 | 复杂的查询 |
| 数据库大小 | 100MB - 100GB | 100GB - 100TB |

## 4. 行式存储和列式存储的区别
+ OLTP的数据存储通常采用行式组织, 处于同一行中的数据总是被物理地存储在一起，常见的行式数据库有：MySQL、Postres SQL、 Oracle等
+ OLAP采用列式组织，将同一列的数据存储在一起，不同列数据也总是分开存储，常见的列式存储数据库有：Vertica、Praccel、Sybase IQ等
+ 列式数据库更适合OLAP场景：
  1. 针对分析查询类，通常只需要读取表得一小部分列，在列式数据库中可以只读取需要的数据，减少I/O消耗
  2. 由于数据总是打包成批读取，方便压缩，同时数据按列存储更容易压缩，进一步降低I/O消耗
  3. 由于I/O消耗降低，将帮助更多的数据被系统缓存

# 五、数据仓库和数据库的区别
在设计数据仓库模型和架构时，我们需要懂具体的技术，也需要了解行业的知识和经验来帮助我们对业务进行抽象、处理，进而生成各个阶段的模型

## 1. 数据模型架构
+ 系统记录域：数据仓库业务数据存储区，保证数据的一致性
+ 内部管理域：统一地管理内部的元数据
+ 汇总域：汇总来自系统记录域的数据，保证分析域的主题分析性能，满足部分报表查询
+ 分析域：对各个业务部分的具体主题进行业务分析，可以单独存储在相应的数据集市中
+ 反馈域：用于相应的前端的反馈数据，视业务的需要设置这个域

## 2. 多维数据模型
多维数据模型是为了满足用户从多角度多层次进行数据查询和分析的需要而建立起来的基于事实和维的数据库模型，其基本的应用是为了实现OLAP

当然，通过多维数据模型的数据展示、查询和获取就是其作用的展现，但其真的作用的实现在于，通过数据仓库可以根据不同的数据需求建立起各类多维模型，并组成数据集市开放给不同的用户群体使用，也就是根据需求定制的各类数据商品摆放在数据集市中供不同的数据消费者进行采购

> 事实表
事实表(Fact Table)：是指存储有事实记录的表，如系统的日志、销售记录、用户访问日志等信息，事实表的记录是动态的增长的，其体积是大于维度表

> 维度表
维度表(Dimension Table)：也称为查找表（Lookup Table）是与事实表相对应的表，这个表保存了维度的属性值，可以跟事实表做关联，相当于是将事实表中经常重复的数据抽取、规范出来用一张表管理。如日期（日、周、月、季度、年等属性）、地区表等

+ 维度表的变化通常不会太大， 主要用来描述用户关心的业务数据，如销售数量，库存数量，销售金额等
+ 维度表的存在缩小了事实表的大小，便于维度的管理和CURD维度的属性，不必对事实表的大量记录进行改动，并且可以给多个事实表重用
+ 基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型，在设计逻辑型数据的模型的时候，就应考虑数据是按照星型模型还是雪花型模型进行组织

## 3. 星型模型和雪花型模型的区别
> 星型模型： 所有维表都直接连接到事实表上
![星型模型](https://pic3.zhimg.com/v2-1d39380d9238ca7c5876ac92d27750b2_b.jpg)
+ 星型架构是一种非正规化的结构，有一张事实表和多张维度表，设计与实现都比较简单
+ 多维数据集的每一个维度都直接与事实表相连接，不存在渐变维度，所以数据有一定的冗余，因为维度表的数据冗余，所以统计查询时不需要做过多外部连接, 因此一般情况下效率比雪花型模型要高
+ 事实表和维度表通过主外键相关联，维度表之间是没有关联

> 雪花型模型：有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上
![雪花型模型](https://pic4.zhimg.com/v2-e7e1a7403be3ffb217f623d89771a573_b.jpg)
+ 雪花模型是一种正规化的结构，是对星型模型的扩展，它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 "层次 " 区域，这些被分解的表都连接到主维度表而不是事实表
+ 雪花模型通过最大限度地减少数据存储量以及联合较小的维表来改善查询性能，去除了数据冗余

> 星型模型 VS 雪花型模型
+ 雪花模型使用的是规范化数据，也就是说数据在数据库内部是组织好的，以便消除冗余，因此它能够有效地减少数据量。通过引用完整性，其业务层级和维度都将存储在数据模型之中
+ 星形模型实用的是反规范化数据。在星形模型中，维度直接指的是事实表，业务层级不会通过维度之间的参照完整性来部署
+ 在雪花模型中，数据模型的业务层级是由一个不同维度表主键-外键的关系来代表的。而在星形模型中，所有必要的维度表在事实表中都只拥有外键
+ 在冗余可以接受的前提下，实际运用中星型模型使用更多，也更有效率
+ 雪花模型在维度表、事实表之间的连接很多，因此性能方面会比较低，星形模型的连接就少的多，性能较好
+ 雪花模型加载数据集市，因此ETL操作在设计上更加复杂，而且由于附属模型的限制，不能并行化
+ 星形模型加载维度表，不需要再维度之间添加附属模型，因此ETL就相对简单，而且可以实现高度的并行化

总结：
+ 雪花模型使得维度分析更加容易，星形模型用来做指标分析更适合
+ 星型有时候规范化和效率是一组矛盾。一般我们会采取牺牲空间（规范化）来换取好的性能，把尽可能多的维度信息存在一张“大表”里面是最快的。通常会视情况而定，采取折中的策略
+ 星型有时会造成数据大量冗余，并且很有可能将事实表变的及其臃肿（上百万条数据×上百个维度）。每次遇到需要更新维度成员的情况时，都必须连事实表也同时更新。而雪花型，有时只需要更新雪花维度中的一层即可，无需更改庞大的事实表。具体问题具体分析，如时间维度，年，季就没必要做雪花，而涉及到产品和产品的分类，如果分类信息也是我们需要分析的信息，那么，我肯定是建关于分类的查找表，也就是采用雪花模式
+ 雪花型结构是一种正规化结构，它去除了数据仓库中的冗余数据。比如有一张销售事实表，然后有一张产品维度表与之相连，然后有一张产品类别维度表与产品维度表连。这种结构就是雪花型结构。雪花型结构取除了数据冗余，所以有些统计就需要做连接才能产生，所以效率不一定有星型架构高。正规化也是一种比较复杂的过程，相应数据库结构设计、数据的ETL、以及后期的维护都要复杂一些
+ 星型架构是一种非正规化的结构，多维数据集中的每一个维度都与事实表相连接，不存在渐变维度，所以数据有一定的冗余，正因为数据的冗余所以很多统计查询不需要做外部的连接所以一般情况下效率比雪花型要高。星型结构不用考虑很多正规化的因素，设计与实现都比较简单

## 4. 数据模型建立的过程
1. 业务模型：业务分解和程序化，确定好业务的边界及业务流程，如订单、支付都是一个单独的业务模块
2. 领域模型：业务概念的抽象、分组，整理分组之间的关联，比如用户购物的业务，抽成一个更大的模型，这个模型一般相对于行业
3. 逻辑建模：领域模型中的业务概念实体化，并考虑实体的具体属性及实体与实体之间的关系，比如订单（订单号、付款人…）和支付（金额、支付时间…）的关系
4. 物理模型：解决实际应用的落地开发、上线等问题，及性能等一些具体的技术问题

# 六、 数据仓库分层
## 1. 为什么要分层及好处
在未分层的情况下，数据和业务之间的耦合性是不可避免的，当源业务系统的业务规则发生变化时，可能影响整个数据的清洗过程。数据分层简化了数据清洗的过程，使得每一层的逻辑变得更加简单和易于理解，当发生错误或规则变化时，只需要进行局部调整。

分层的好处包括以下三点：
+ 将复杂工作拆分成多个简单步骤：数据仓库通过分层，将工作分成了多个步骤，相当于把一个复杂的工作拆分成了多个简单的工作，这样每一层的分工都很简单和明确。当数据发生错误的时候，只需要逐层溯源，找到产生错误的步骤并调整这个步骤即可
+ 将数据与业务变化隔离：公司业务与需求经常会发生变化，如果不分层，数据仓库需要对每次业务与需求的变化进行重新清晰、计算数据，而使用分层设计，数据仓库只需要调整与变化最接近的一层即可，起到将数据与业务分离的作用
+ 用空间换时间：数据仓库的分层实际上是提前将可能需要用到的数据计算出来并存储，这样当我们需要数据的时候就可以直接使用而不必计算了，提升用户体验和效率

## 2. 数据仓库分层
### 2.1 ODS层
ODS(Operational Data Store)为数据操作层，又称为数据准备层、数据来源层。通常将日志数据或关系型数据库，通过Flume、sqoop、Kettle等ETL工具导入到HDFS，并映射到Hive的数据仓库表中。主要用于原始数据在数据平台的落地，这些数据从数据结构，数据之间的逻辑上都与原始数据保持一致。在源数据装入这一层，要进行诸如业务字段提取、去掉不同字段或脏数据处理等，可以理解为关系层的基础数据
> 特点:
+ 数据结构：数据结构与原始数据基本保持一致
+ 存储周期：默认保留近30天的数据
+ 表命名规范：ods_主题_表内容_分表规则
> 数据的来源方式
+ 业务库：经常会使用sqoop来抽取，比如每天定时抽取一次。在实时方面，可以考虑用Canal监听MySQL的binlog，实时接入即可
+ 埋点日志：线上系统会打入各种日志，这些日志一般以文件的形式保存，我们可以选择用Flume定时抽取，也可以使用Spark streaming或storm来实时接入。当然kafka也是一个关键的角色
+ 其他数据源：和具体业务相关

### 2.2 DIM层
DIM为公共的信息层，主要存放公共的信息数据。如国家代码和国家名，地理位置等就存在DIM层中，对外开放，用于DWD、DWS和APP层的数据维度关联，可以理解为一些字典表、单独存放
> 特点：
+ 数据结构：维表，存放所有公共信息数据的主键
+ 存储周期：按需存储，一般会保留历史至今的所有数据
+ 表命名规范：dim.dim_业务描述(所有维度表都在DIM下)

### 2.3 DWD层
DWD(Data Warehouse Detail)为数据明细层，用于源系统数据在数据平台中的永久存储，用以支撑DWS层和DM层无法覆盖的需求，主要解决一些数据质量和数据完整度问题，该层的数据模型数据不建议给不懂技术的业务人员直接使用
> 特点：
+ 数据结构：数据结构与源系统保持一致
+ 存储周期：保留历史至今所有的数据
+ 命名规范：dwd.dwd_业务描述_时间粒度

### 2.4 DWS层
DWS(Data Warehouse Service)为数据汇总层，主要包含两类汇总表：细粒度宽表和粗粒度汇总表，该层时对外开放的，用以支持绝大部分业务需求(能满足80%的业务计算),该层简化了源系统复杂的逻辑关系，使得业务结构更容易理解，各个层面的工程师更容易上手
> 特点
+ 数据结构：宽表-以业务实体进行展开，将与业务有关的相关字段和属性进行关联、预处理和预计算，对业务实体进行拉伸形成宽表；汇总表-多个维度组合形成汇总表
+ 存储周期：原则上保留历史至今所有的数据
+ 命名规范：dws.dws_业务描述_时间粒度_sum(所有数据汇总层的表都放在DWS下)

## 3. 数仓分层 - 阿里
### 3.1 ODS(数据准备层)
+ 功能：ODS层是数据仓库准备区，为DWD层提供基础原始数据，可减少对业务系统的影响
+ 建模方式及原则：从业务系统增量抽取、保留时间由业务需求决定、可分表进行周期存储、数据不做清洗转换与业务系统数据模型保持一致、按主题逻辑划分

### 3.2 DWD(数据明细层)
+ 功能：为DW层提供来源明细数据，提供业务系统细节数据的长期沉淀，为未来分析类需求的扩展提供历史数据支撑
+ 建模方式及原则：数据模型与ODS层一致，不做清晰转换处理、为支持数据重跑可额外增加数据业务日期字段、可按年月日进行分表、用增量ODS层数据和前一天DWD相关表进行Merge处理

### 3.3 DW(B/S)(数据汇总层)
+ 功能：为DW、ST层提供细粒度数据，细化成DWB合DWS；DWB是根据DWD明细数据经行清晰转换，如维度转代理键、身份证清洗、会员注册来源清晰、字段合并、空值处理、脏数据处理、IP清晰转换、账号余额清洗、资金来源清洗等；DWS是根据DWB层数据按各个维度ID进行粗粒度汇总聚合，如按交易来源，交易类型进行汇合
+ 建模方式及原则：聚合、汇总增加派生事实；关联其它主题的事实表，DW层可能会跨主题域；DWB保持低粒度汇总加工数据，DWS保持高粒度汇总数据； 数据模型可能采用反范式设计，合并信息等

### 3.4 DM(数据集市层)
+ 功能：可以是一些宽表，是根据DW层数据按照各种维度或多种维度组合把需要查询的一些事实字段进行汇总统计并作为单独的列进行存储；满足一些特定查询、数据挖掘应用；应用集市数据存储
+ 建模方式及原则：尽量减少数据访问时计算，优化检索；维度建模，星型模型； 事实拉宽，度量预先计算；分表存储

### 3.5 ST(数据应用层)
+ 功能：：ST层面向用户应用和分析需求，包括前端报表、分析图表、KPI、仪表盘、OLAP、专题等分析，面向最终结果用户；适合作OLAP、报表模型，如ROLAP,MOLAP；根据DW层经过聚合汇总统计后的粗粒度事实表
+ 建模方式及原则：保持数据量小；维度建模，星形模型；各位维度代理键+度量；增加数据业务日期字段，支持数据重跑；不分表存储

### 结构特点
+ 细化DW建模：对DW中各个主题业务建模进行了细分，每个层次具有不同的功能；保留了最细粒度数据；满足了不同维度、不同事实的信息
+ 满足数据重新生成：不同层次的数据支持数据重新生成；无需备份恢复；解决了由不同故障带来的数据质量问题；消除了重新初始化数据的烦恼
+ 减少应用对DW的压力：以业务应用驱动为导向建模，通过ST、DW层提供数据。避免直接操作基础事实表；降低数据获取时间
+ 快速适应需求变更：适应维度变化；明细基础数据层稳定；适应前应用层业务需求变更；所有前端应用层模型之间不存在依赖，需求变更对DW整个模型影响范围小；能适应短周期内上线下线需求

![DW五层模型架构介绍](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%5BDW%E4%BA%94%E5%B1%82%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.jpg)

# 七、 创建数仓步骤
+ 确定主题: 即确定数据分析或前端展现的主题(例:某年某月某地区的啤酒销售情况)。主题要体现出某一方面的各分析角度(维度)和统计数值型数据(量度)之间的关系,确定主题时要综合考虑
+ 确定量度: 确定主题后，需要考虑分析的技术指标(例:年销售额等等)。它们一般为数据值型数据，其中有些度量值不可以汇总；有些可以汇总起来，以便为分析者提供有用的信息。量度是要统计的指标，必须事先选择恰当，基于不同的量度可以进行复杂关键性指标(KPI)的设计和计算
+ 确定事实数据粒度: 确定量度之后，需要考虑该量度的汇总情况和不同维度下量度的聚合情况。例如在业务系统中数据最小记录到秒，而在将来分析需求中，时间只要精确到天就可以了，在ETL处理过程中，按天来汇总数据时数据仓库中量度的粒度就是”天”。如果不能确认将来的分析需求中是否要精确的秒，那么，我们要遵循”最小粒度原则”。在数据仓库中的事实表中保留每一秒的数据，从而在后续建立多维分析模型(CUBE)的时候,会对数据提前进行汇总，保障产生分析结果的效率
+ 确定维度：维度是分析的各个角度，基于不同的维度，可以看到各个量度汇总的情况，也可以基于所有的维度进行交叉分析。例如：我们希望按照时间、或地区，或产品进行分析，那么这里的时间，地区，产品就是相应的维度。   
  同时要明确维度的层次(Hierarchy)和级别(Level)。例如：在时间维度上，按照”年-季度-月”形成了一个层次，其中”年” ,”季度” ,”月”成为了该层次的3个级别；我们可以将“产品大类-产品子类-产品”划为一个层次，其中包含“产品大类”、“产品子类”、“产品”三个级别。我们可以将3个级别设置成一张数据表中的3个字段,比如时间维度；我们也可以使用三张表，分别保存产品大类，产品子类，产品三部分数据,比如产品维度   
  建立维度表时要充分使用代理键。代理键是数据值型的ID号码(每张表的第一个字段)，它唯一标识了第一维度成员。在聚合时，数值型字段的匹配、比较和join效率高，同时代理键在缓慢变化维中，起到了对新数据与历史数据的标识作用
+ 创建事实表： 在确定好事实数据和维度后，将考虑加载事实表。业务系统的的一笔笔生产，交易记录就是将要建立的事实表的原始数据，我们的做法是将原始表与维度表进行关联，生成事实表。   
  关联时有为空的数据时(数据源脏)，需要使用外连接，连接后将各维度的代理键取出放于事实表中，事实表除了各维度代理键外，还有各度量数据，不应该存在描述性信息
  事实表中的记录条数据都比较多，要为其设置复合主键索引，以实现数据的完整性和基于数据仓库的查询性能优化

# 八、 数据仓库的应用
+ 信息处理: 支持查询、基础的统计分析，并使用交叉表、表、图标和图进行报表处理
+ 分析处理：对数据仓库中的数据进行多维数据分析，支持基本的OLAP操作，切块、切片、上卷、下钻、转轴等
+ 数据挖掘：从隐藏模式中发现知识，支持关联分析，构建分析性模型，分类和预测，并用可视化工具呈现挖掘的结果

# 九、 数据分析与数据挖掘的区别和联系
![数据分析与数据挖掘的区别和联系](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%92%8C%E6%95%B0%E5%88%86%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB.jpg)

# 十、常见面试题
## 1. 手写“从'2020-08-10'起，员工连续7天打卡”的SQL
```sql
// 根据实际需求进行相应操作
select t3.user_id, t3.count_day   
  // 根据用户id和日期差聚合算出连续打卡天数count_day --> 此时以获取员工连续打卡天数表格   
  (select t2.user_id, t2.diff_date, count(1) as count_day from   
   // 根据排序结果获取日期差-->日期差相等则连续   
   (select t1.user_id, t1.date_id, date_sub(t1.date_id, rn) as diff_date from   
    // 根据筛选条件在where中取出数据后，使用开窗函数按用户id聚合、日期增序排序   
    (select user_id, date_id, row_number() over(partition by user_id order by date_id) rn from events    
      where date_id>='2020-08-10' and success=1) t1   
     ) t2   
     group by user_id, diff_date) t3   
 where t3.count_day >=7;
```

## 2. 维度建模和范式建模的区别
范式建模，即3NF模型具有以下特点:
+ (1NF) 原子性，即数据不可分割
+ (2NF) 基于第一个条件，实体属性完全依赖于主键，不能存在仅依赖主关键字一部分属性， 即不能存在部分依赖
+ (3NF) 基于第二个条件，任何非主属性不依赖于其他非主属性。即消除传递依赖
基于以上三个特点，3NF的最终目的就是为了降低数据冗余，保障数据一致性,，同时也有了数据关联逻辑复杂的缺点

维度建模是面向分析场景的，主要关注点在于快速、灵活，能够提供大规模的数据响应：
+ 星型模型：即由一个事实表和一组维度表组成，每个维表都有一个维度作为主键，事实表居中，多个维表呈辐射状分布在四周，并与事实表关联，形成一个星型结构 ([星型模型图](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B.jpg)）
+ 雪花模型：在星型模型的基础上，基于范式理论进一步层次化，将某些维表扩展成事实表，最终形成雪花状结构（[雪花模型图](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%9E%8B.png)）
+ 星座模型：基于多个事实表，共享一些维度表（[星座模型图](https://github.com/guojinshan/Keep_learning/blob/main/Data%20WareHouse/%E6%98%9F%E5%BA%A7%E6%A8%A1%E5%9E%8B.png)）

## 3. 数据漂移如何解决
> 什么是数据漂移？
通常是指ods表的同一个业务日期数据中包含了前一天或后一天凌晨附近的数据或者丢失当天变更的数据，这种现象就叫做漂移，且在大部分公司中都会遇到的场景

> 如何解决数据漂移问题？
+ 方案一：多获取后一天的数据，保障数据只多不少 (暴力)
+ 方案二：通过多个时间戳字段来限制时间获取相对准确的数据

通常，时间戳字段分为四类：
1. 数据库表中用来标识数据**记录更新时间**的时间戳字段（假设这类字段叫 modified time）
2. 数据库日志中用来标识**数据记录更新时间**的时间戳字段·（假设这类宇段叫 log_time）
3. 数据库表中用来记录**具体业务过程发生时间**的时间戳字段 （假设这类字段叫 proc_time）
4. 标识数据记录**被抽取到时间**的时间戳字段（假设这类字段extract time）

理论上这几个时间应该是一致的，但往往会出现差异，造成的原因可能为：
1. 数据抽取需要一定的时间，extract_time往往晚于前三个时间
2. 业务系统手动改动数据并未更新modfied_time
3. 网络或系统压力问题，log_time或modified_time晚于proc_time
通常都是根据以上的某几个字段来切分ODS表，这就产生了数据漂移，具体场景如下：
1. 根据extract_time进行同步
2. 根据modified_time进行限制同步， 在实际生产中这种情况最常见，但是往往会发生不更新 modified time 而导致的数据遗漏，或者凌晨时间产生的数据记录漂移到后一天，由于网络或者系统压力问题， log_time 会晚proc_time ，从而导致凌晨时间产生的数据记录漂移到后一天
3. 根据proc_time来限制，会违背ods和业务库保持一致的原则，因为仅仅根据proc_time来限制，会遗漏很多其他过程的变化

具体解决方案步骤:
1. 首先通过log_time多同步前一天最后15分钟和后一天凌晨开始15分钟的数据，然后用modified_time过滤非当天的数据，这样确保数据不会因为系统问题被遗漏
2. 然后根据log_time获取后一天15分钟的数据，基于这部分数据，按照主键根据log_time做升序排序，那么第一条数据也就是最接近当天记录变化的
3. 最后将前两步的数据做全外连接，通过限制业务时间proc_time来获取想要的数据

## 4. 拉链表如何设计，拉链表出现数据回滚的需求怎么解决
拉链表使用的场景：
+ 数据量大，且表中部分字段会更新，比如用户地址、产品描述信息、订单状态等等
+ 需要查看某一个时间段的历史快照信息
+ 变化比例和频率不是很大

```sql
  --拉链表实现
  --原始数据
  CREATE TABLE wedw_tmp.tmp_orders (
      orderid INT,
      createtime STRING,
      modifiedtime STRING,
      status STRING
  ) stored AS textfile;
  
 --拉链表
 CREATE TABLE wedw_tmp.tmp_orders_dz(
     orderid int,
     createtime STRING,
     modifiedtime STRING,
     status STRING,
     link_start_date string,
     link_end_date string
 ) stored AS textfile;
 
 --更新表
 CREATE TABLE wedw_tmp.tmp_orders_update(
     orderid INT,
     createtime STRING,
     modifiedtime STRING,
     status STRING
 ) stored AS textfile;
 
 --插入原始数据
 insert overwrite table  wedw_tmp.tmp_orders
 select 1,"2015-08-18","2015-08-18","创建"
 union all 
 select 2,"2015-08-18","2015-08-18","创建"
 union all
 select 3,"2015-08-19","2015-08-21","支付"
 union all
 select 4,"2015-08-19","2015-08-21","完成"
 union all 
 select 5,"2015-08-19","2015-08-20","支付"
 union all 
 select 6,"2015-08-20","2015-08-20","创建"
 union all 
 select 7,"2015-08-20","2015-08-21","支付"
 
 --拉链表初始化
 insert into  wedw_tmp.tmp_orders_dz
 select *,createtime,'9999-12-31'  from  wedw_tmp.tmp_orders
 
 --增量数据
 insert into  wedw_tmp.tmp_orders_update
 select 3,"2015-08-19","2015-08-21","支付"
 union all
 select 4,"2015-08-19","2015-08-21","完成"
 union all 
 select 7,"2015-08-20","2015-08-21","支付"
 union all 
 select 8,"2015-08-21","2015-08-21","创建" 
 
 --更新拉链表
 insert overwrite table  wedw_tmp.tmp_orders_dz
 select 
     t1.orderid,
     t1.createtime,
     t1.modifiedtime,
     t1.status,
     t1.link_start_date,
     case when t1.link_end_date='9999-12-31' and t2.orderid is not null then '2015-08-20'
     else t1.link_end_date
     end as link_end_date
 from  wedw_tmp.tmp_orders_dz t1
 left join wedw_tmp.tmp_orders_update t2
 on t1.orderid = t2.orderid
 union all 
 select 
   orderid,
   createtime,
   modifiedtime,
   status,
   '2015-08-21' as link_start_date,
   '9999-12-31' as link_end_date
 from wedw_tmp.tmp_orders_update
 
 --拉链表回滚，比如在插入2015-08-22的数据后，
 -- 回滚2015-08-21的数据，使拉链表与2015-08-20的一致
 -- 具体操作过程如下
 select 
   orderid,
   createtime,
   modifiedtime,
   status,
   link_start_date,
   link_end_date
 from wedw_tmp.tmp_orders_dz
 where link_end_date<'2015-08-20'
 union all 
 select 
   orderid,
   createtime,
   modifiedtime,
  status,
  link_start_date,
  '9999-12-31'
from wedw_tmp.tmp_orders_dz
where link_end_date='2015-08-20'
union all 
select 
  orderid,
  createtime,
  modifiedtime,
  status,
  link_start_date,
  '9999-12-31'
from wedw_tmp.tmp_orders_dz
where link_start_date<'2020-08-21' and  link_end_date>='2015-08-21'
```

## sql里面on和where有区别吗
数据库在通过连接两张或多张表来返回记录时，都会生成一张中间的临时表。以 LEFT JOIN 为例：在使用 LEFT JOIN 时，ON 和 WHERE 过滤条件的区别如下：
+ on 条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录
+ where 条件是在临时表生成好后，再对临时表进行过滤的条件，这时已经没有 left join 的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉

# 公共层和数据集市层的区别和特点
公共维度模型层(CDM), 又细分为dwd层和dws层，主要存放明细事实数据、维表数据以及公共指标汇总数据，其中明细事实数据、维表数据一般是根据ods层数据加工生成的，公共指标汇总数据一般是基于维表和明细事实数据加工生成的

采用维度模型方法作为理论基础，更多采用一些维度退化的手段，将维度退化到事实表中，减少事实表和维度表之间的关联。同时在汇总层，加强指标的维度退化，采用更多的宽表化手段构建公共指标数据层，提升公共指标的复用性，减少重复加工

其主要功能：
1. 组合相关和相似数据：采用明细宽表，复用关联计算，减少数据扫描
2. 公共指标统一加工：基于 OneData 体系构建命名规范、口径一致 和算法统一的统计指标，为上层数据产品、应用和服务提供公共指标建立逻辑汇总宽表
3. 建立一致性维度：建立一致的数据分析维表，降低数据计算口径、 算法不统一的风险。应用数据层（ ADS）：存放数据产品个性化的统计指标数据，根据 CDM 层与 ODS 层加工生成

数据集市(Data Mart): 是满足特定部门或者用户的需求，按照多维方式存储，面向决策分析的数据立方体

[回看链接](https://my.oschina.net/u/4631230/blog/4688808)
